#!/usr/bin/env python3
"""
TWSE Snapshot ä¸²æµè™•ç†ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ data_v3.py è™•ç†å¤§å‹æª”æ¡ˆè€Œä¸æœƒ OOM
"""

from pathlib import Path
from data_v3 import SnapshotParser
import time

def demo_basic_streaming():
    """åŸºæœ¬ä¸²æµè™•ç†ç¤ºä¾‹"""
    print("ğŸ¯ ç¤ºä¾‹ 1: åŸºæœ¬ä¸²æµè™•ç†")
    print("-" * 40)
    
    parser = SnapshotParser()
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    input_file = "snapshot/Sample_new.gz"
    if not Path(input_file).exists():
        input_file = "snapshot/Sample_new"
        if not Path(input_file).exists():
            print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆï¼Œè«‹ç¢ºä¿ snapshot/ ç›®éŒ„ä¸­æœ‰è³‡æ–™")
            return
    
    print(f"ğŸ“‚ è™•ç†æª”æ¡ˆ: {input_file}")
    
    # å–®ä¸€æª”æ¡ˆä¸²æµè™•ç†
    start_time = time.time()
    parser.stream_dsp_to_parquet(
        input_file,
        "demo_output/single_file.parquet",
        chunk_size=100_000,
        compression="zstd",
        compression_level=3
    )
    end_time = time.time()
    
    print(f"â±ï¸  è™•ç†æ™‚é–“: {end_time - start_time:.2f} ç§’")
    print(f"âœ… è¼¸å‡º: demo_output/single_file.parquet")

def demo_partitioned_streaming():
    """åˆ†å‰²å­˜å„²ä¸²æµè™•ç†ç¤ºä¾‹"""
    print("\nğŸ¯ ç¤ºä¾‹ 2: åˆ†å‰²å­˜å„²ä¸²æµè™•ç†")
    print("-" * 40)
    
    parser = SnapshotParser()
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    input_file = "snapshot/Sample_new.gz"
    if not Path(input_file).exists():
        input_file = "snapshot/Sample_new"
        if not Path(input_file).exists():
            print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆ")
            return
    
    print(f"ğŸ“‚ è™•ç†æª”æ¡ˆ: {input_file}")
    
    # åˆ†å‰²å­˜å„²ä¸²æµè™•ç†
    start_time = time.time()
    parser.stream_dsp_to_partitioned_parquet(
        input_file,
        "demo_output/partitioned/",
        chunk_size=50_000,
        compression="zstd",
        max_open_files=50  # é™åˆ¶åŒæ™‚é–‹å•Ÿçš„æ–‡ä»¶æ•¸é‡ï¼Œé¿å…"Too many open files"éŒ¯èª¤
    )
    end_time = time.time()
    
    print(f"â±ï¸  è™•ç†æ™‚é–“: {end_time - start_time:.2f} ç§’")
    print(f"âœ… è¼¸å‡º: demo_output/partitioned/")
    
    # é¡¯ç¤ºç”Ÿæˆçš„æª”æ¡ˆçµæ§‹
    output_dir = Path("demo_output/partitioned")
    if output_dir.exists():
        print("\nğŸ“ ç”Ÿæˆçš„æª”æ¡ˆçµæ§‹:")
        for date_dir in sorted(output_dir.iterdir()):
            if date_dir.is_dir():
                print(f"  ğŸ“… {date_dir.name}/")
                for parquet_file in sorted(date_dir.glob("*.parquet")):
                    file_size = parquet_file.stat().st_size / 1024  # KB
                    print(f"    ğŸ“Š {parquet_file.name} ({file_size:.1f} KB)")

def demo_chunk_size_comparison():
    """ä¸åŒ chunk_size çš„æ•ˆèƒ½æ¯”è¼ƒ"""
    print("\nğŸ¯ ç¤ºä¾‹ 3: Chunk Size æ•ˆèƒ½æ¯”è¼ƒ")
    print("-" * 40)
    
    parser = SnapshotParser()
    
    input_file = "snapshot/Sample_new.gz"
    if not Path(input_file).exists():
        input_file = "snapshot/Sample_new"
        if not Path(input_file).exists():
            print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆ")
            return
    
    chunk_sizes = [10_000, 50_000, 100_000]
    
    print("æ¸¬è©¦ä¸åŒ chunk_size çš„æ•ˆèƒ½å½±éŸ¿:")
    print("Chunk Size | è™•ç†æ™‚é–“ | è¼¸å‡ºå¤§å°")
    print("-" * 35)
    
    for chunk_size in chunk_sizes:
        output_file = f"demo_output/chunk_test_{chunk_size}.parquet"
        
        start_time = time.time()
        parser.stream_dsp_to_parquet(
            input_file,
            output_file,
            chunk_size=chunk_size,
            show_progress=False  # é¿å…å¹²æ“¾è¼¸å‡º
        )
        end_time = time.time()
        
        processing_time = end_time - start_time
        
        if Path(output_file).exists():
            file_size = Path(output_file).stat().st_size / 1024  # KB
            print(f"{chunk_size:>10,} | {processing_time:>8.2f}s | {file_size:>7.1f} KB")
            
            # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
            Path(output_file).unlink()
        else:
            print(f"{chunk_size:>10,} | {'ERROR':>8} | {'N/A':>7}")

def demo_memory_efficient_processing():
    """è¨˜æ†¶é«”æ•ˆç‡ç¤ºä¾‹"""
    print("\nğŸ¯ ç¤ºä¾‹ 4: è¨˜æ†¶é«”æ•ˆç‡å±•ç¤º")
    print("-" * 40)
    
    try:
        import psutil
        import os
        
        def get_memory_mb():
            process = psutil.Process(os.getpid())
            return process.memory_info().rss / (1024 * 1024)
        
        parser = SnapshotParser()
        input_file = "snapshot/Sample_new.gz" if Path("snapshot/Sample_new.gz").exists() else "snapshot/Sample_new"
        
        if not Path(input_file).exists():
            print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆ")
            return
        
        print("ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§:")
        
        # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”
        initial_memory = get_memory_mb()
        print(f"ğŸŸ¦ åˆå§‹è¨˜æ†¶é«”: {initial_memory:.1f} MB")
        
        # ä¸²æµè™•ç†
        parser.stream_dsp_to_parquet(
            input_file,
            "demo_output/memory_test.parquet",
            chunk_size=50_000,
            show_progress=False
        )
        
        # è¨˜éŒ„è™•ç†å¾Œè¨˜æ†¶é«”
        final_memory = get_memory_mb()
        memory_increase = final_memory - initial_memory
        
        print(f"ğŸŸ© è™•ç†å¾Œè¨˜æ†¶é«”: {final_memory:.1f} MB")
        print(f"ğŸ“ˆ è¨˜æ†¶é«”å¢åŠ : {memory_increase:.1f} MB")
        
        if memory_increase < 100:  # å°‘æ–¼100MBå¢åŠ 
            print("âœ… è¨˜æ†¶é«”ä½¿ç”¨è‰¯å¥½ï¼")
        else:
            print("âš ï¸  è¨˜æ†¶é«”ä½¿ç”¨è¼ƒé«˜ï¼Œè€ƒæ…®æ¸›å°‘ chunk_size")
            
    except ImportError:
        print("âŒ éœ€è¦å®‰è£ psutil ä¾†ç›£æ§è¨˜æ†¶é«”: pip install psutil")

def cleanup_demo_files():
    """æ¸…ç†ç¤ºä¾‹æª”æ¡ˆ"""
    demo_dir = Path("demo_output")
    if demo_dir.exists():
        import shutil
        shutil.rmtree(demo_dir)
        print("ğŸ§¹ å·²æ¸…ç†ç¤ºä¾‹æª”æ¡ˆ")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ TWSE Snapshot ä¸²æµè™•ç†ç¤ºä¾‹")
    print("=" * 50)
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    Path("demo_output").mkdir(exist_ok=True)
    
    try:
        # åŸ·è¡Œç¤ºä¾‹
        demo_basic_streaming()
        demo_partitioned_streaming()
        demo_chunk_size_comparison()
        demo_memory_efficient_processing()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹å®Œæˆï¼")
        print("\nğŸ’¡ å¯¦ç”¨æç¤º:")
        print("  â€¢ å¤§æª”æ¡ˆå»ºè­°ä½¿ç”¨ chunk_size=200_000-500_000")
        print("  â€¢ å£“ç¸®æ ¼å¼ 'zstd' æä¾›æœ€ä½³å£“ç¸®æ¯”")
        print("  â€¢ åˆ†å‰²å­˜å„²é©åˆå¾ŒçºŒæŒ‰è‚¡ç¥¨ä»£ç¢¼æŸ¥è©¢")
        print("  â€¢ å–®ä¸€æª”æ¡ˆé©åˆæ•´é«”æ•¸æ“šåˆ†æ")
        
    except KeyboardInterrupt:
        print("\nâŒ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
    finally:
        # è©¢å•æ˜¯å¦æ¸…ç†æª”æ¡ˆ
        try:
            response = input("\nğŸ—‘ï¸  æ˜¯å¦æ¸…ç†ç¤ºä¾‹æª”æ¡ˆï¼Ÿ[y/N]: ").strip().lower()
            if response in ['y', 'yes']:
                cleanup_demo_files()
        except (EOFError, KeyboardInterrupt):
            print("\nä¿ç•™ç¤ºä¾‹æª”æ¡ˆ")

if __name__ == "__main__":
    main() 